{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Abumaude/AI-Foolosophy/blob/main/AI_AGENTS_lab_8_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Agents and their Types\n",
    "\n",
    "**An agent** is a system or program that can autonomously perform tasks on behalf of a user or another system. These agents interact with their environment, collect data, and use this data to make decisions and take actions to achieve specific goals.\n",
    "\n",
    "**AI agents can vary in complexity and functionality. Here are some key characteristics:**\n",
    "\n",
    "\n",
    "- **Autonomy**: They operate without human intervention, making decisions based on their programming and the data they collect.\n",
    "\n",
    "- **Perception**: They use sensors or data inputs to perceive their environment.\n",
    "\n",
    "- **Action**: They can take actions to influence their environment, such as moving, speaking, or making decisions.\n",
    "\n",
    "- **Rationality**: They aim to achieve their goals in the most efficient way possible, often using algorithms to determine the best course of action.\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "eDn8biBDuwtq"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**AI agents** can be categorized into several types based on their capabilities and how they interact with their environment. Here are the main types:\n",
    "\n"
   ],
   "metadata": {
    "id": "dxUqd0Aivu1_"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**1- Simple Reflex Agents**: These agents act only based on the current percept, ignoring the rest of the percept history. They follow a set of predefined rules to respond to specific situations. For example, a thermostat that turns on the heater when the temperature drops below a certain point.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "YCimuyMdEJCw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define a simple reflex agent for a thermostat\n",
    "class ThermostatAgent:\n",
    "    def __init__(self, temperature_threshold):\n",
    "        self.temperature_threshold = temperature_threshold\n",
    "        self.heater_on = False\n",
    "\n",
    "    def perceive(self, current_temperature):\n",
    "        self.current_temperature = current_temperature\n",
    "\n",
    "    def act(self):\n",
    "        if self.current_temperature < self.temperature_threshold:\n",
    "            self.heater_on = True\n",
    "            print(\"Heater turned ON\")\n",
    "        else:\n",
    "            self.heater_on = False\n",
    "            print(\"Heater turned OFF\")\n",
    "\n",
    "# Example usage\n",
    "thermostat = ThermostatAgent(20)  # Threshold temperature is 20 degrees\n",
    "\n",
    "# Simulate temperature readings\n",
    "temperatures = [18, 22, 19, 25, 15]\n",
    "\n",
    "for temp in temperatures:\n",
    "  thermostat.perceive(temp)\n",
    "  thermostat.act()"
   ],
   "metadata": {
    "id": "QdaVJBEBv_BK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "735d2c1d-be49-4451-fa95-03723cbbcc9b"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Heater turned ON\n",
      "Heater turned OFF\n",
      "Heater turned ON\n",
      "Heater turned OFF\n",
      "Heater turned ON\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 1: Simple Reflex Agent**:\n",
    "   - **Description**: Implement a simple reflex agent for a basic environment, such as a vacuum cleaner that cleans a room.\n",
    "   - **Requirements**: The agent should move around a grid and clean any dirty spots it encounters based on predefined rules."
   ],
   "metadata": {
    "id": "apyIxi8IMpjK"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2- Model-Based Reflex Agents:** These agents maintain an internal model of the world, which helps them handle more complex situations by considering the history of percepts. They can make decisions based on both current and past information."
   ],
   "metadata": {
    "id": "yfcGRXDUwNMh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Model-Based Reflex Agents Example (Expanding on the Thermostat)\n",
    "\n",
    "class ModelBasedThermostatAgent:\n",
    "    def __init__(self, temperature_threshold, learning_rate=0.1):\n",
    "        self.temperature_threshold = temperature_threshold\n",
    "        self.heater_on = False\n",
    "        self.internal_temperature_model = 20  # Initial temperature guess\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def perceive(self, current_temperature):\n",
    "        self.current_temperature = current_temperature\n",
    "\n",
    "    def update_model(self):\n",
    "        # Simple model update based on current temperature and error\n",
    "        error = self.current_temperature - self.internal_temperature_model\n",
    "        self.internal_temperature_model += error * self.learning_rate\n",
    "\n",
    "    def act(self):\n",
    "        self.update_model()  # Update the model first\n",
    "\n",
    "        if self.internal_temperature_model < self.temperature_threshold:\n",
    "            self.heater_on = True\n",
    "            print(f\"Heater turned ON (Model temp: {self.internal_temperature_model:.2f}, Actual temp: {self.current_temperature})\")\n",
    "        else:\n",
    "            self.heater_on = False\n",
    "            print(f\"Heater turned OFF (Model temp: {self.internal_temperature_model:.2f}, Actual temp: {self.current_temperature})\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "model_thermostat = ModelBasedThermostatAgent(20)\n",
    "\n",
    "# Simulate temperature readings\n",
    "temperatures = [18, 22, 19, 25, 15]\n",
    "\n",
    "for temp in temperatures:\n",
    "    model_thermostat.perceive(temp)\n",
    "    model_thermostat.act()"
   ],
   "metadata": {
    "collapsed": true,
    "id": "g0cKA7PlxGhP",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e8e98853-e6d5-462f-9708-099a48387c59"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Heater turned ON (Model temp: 19.80, Actual temp: 18)\n",
      "Heater turned OFF (Model temp: 20.02, Actual temp: 22)\n",
      "Heater turned ON (Model temp: 19.92, Actual temp: 19)\n",
      "Heater turned OFF (Model temp: 20.43, Actual temp: 25)\n",
      "Heater turned ON (Model temp: 19.88, Actual temp: 15)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 2: Model-Based Reflex Agent**:\n",
    "   - **Description**: Enhance the vacuum cleaner agent to remember which spots it has already cleaned.\n",
    "   - **Requirements**: The agent should maintain an internal state to avoid re-cleaning the same spot.\n"
   ],
   "metadata": {
    "id": "hFe1NDKpMyWH"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**3- Goal-Based Agents**: These agents act to achieve specific goals. They use their internal model to evaluate different actions and choose the one that brings them closer to their goal. For instance, a navigation system that plans a route to a destination."
   ],
   "metadata": {
    "id": "yWec25DAwnN7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Goal-Based Agent Example (Navigation)\n",
    "\n",
    "class NavigationAgent:\n",
    "    def __init__(self, destination):\n",
    "        self.destination = destination\n",
    "        self.current_location = (0, 0)  # Initial location\n",
    "        self.map = {  # Simplified map representation\n",
    "            (0, 0): [(1, 0), (0, 1)],\n",
    "            (1, 0): [(0, 0), (2, 0)],\n",
    "            (0, 1): [(0, 0), (0, 2)],\n",
    "            (2, 0): [(1, 0)],\n",
    "            (0, 2): [(0,1), (1,2)],\n",
    "            (1,2): [(0,2), (2,2)],\n",
    "            (2,2): [(1,2)]\n",
    "        }\n",
    "\n",
    "    def perceive(self, current_location):\n",
    "        self.current_location = current_location\n",
    "\n",
    "    def plan_route(self):\n",
    "      # Simple route planning (replace with a better algorithm)\n",
    "      queue = [(self.current_location, [self.current_location])]\n",
    "      visited = set()\n",
    "      while queue:\n",
    "          current, path = queue.pop(0)\n",
    "          if current == self.destination:\n",
    "              return path\n",
    "          visited.add(current)\n",
    "          for neighbor in self.map.get(current, []):\n",
    "              if neighbor not in visited:\n",
    "                  queue.append((neighbor, path + [neighbor]))\n",
    "      return None\n",
    "\n",
    "\n",
    "    def act(self):\n",
    "        route = self.plan_route()\n",
    "        if route:\n",
    "            if len(route) > 1:\n",
    "                next_location = route[1]\n",
    "                print(f\"Moving from {self.current_location} to {next_location}\")\n",
    "                self.current_location = next_location # Update current location\n",
    "            else:\n",
    "                print(f\"Arrived at destination {self.destination}\")\n",
    "\n",
    "        else:\n",
    "            print(\"No route found to the destination.\")\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "navigator = NavigationAgent((2, 2))\n",
    "\n",
    "# Simulate the agent's journey\n",
    "locations = [(0,0), (1,0), (2,0), (1,0), (0,1), (0,2), (1,2), (2,2)]\n",
    "\n",
    "for location in locations:\n",
    "  navigator.perceive(location)\n",
    "  navigator.act()"
   ],
   "metadata": {
    "id": "tDmnZyXvxqwR",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "10ec7329-cc91-4281-b0d6-b7d976499a6f"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Moving from (0, 0) to (0, 1)\n",
      "Moving from (1, 0) to (0, 0)\n",
      "Moving from (2, 0) to (1, 0)\n",
      "Moving from (1, 0) to (0, 0)\n",
      "Moving from (0, 1) to (0, 2)\n",
      "Moving from (0, 2) to (1, 2)\n",
      "Moving from (1, 2) to (2, 2)\n",
      "Arrived at destination (2, 2)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 3: Goal-Based Agent**:\n",
    "   - **Description**: Implement a navigation agent that finds the shortest path to a goal in a maze.\n",
    "   - **Requirements**: The agent should use a search algorithm (e.g., A*) to reach the goal efficiently.\n"
   ],
   "metadata": {
    "id": "QfO1TtE-MynE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**4- Utility-Based Agents**: These agents not only aim to achieve goals but also consider the best way to achieve them by evaluating the utility (or value) of different actions. They strive to maximize their performance measure.\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "MAiP9fPHyBBA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Utility-Based Agent Example (Resource Allocation)\n",
    "\n",
    "class ResourceAllocationAgent:\n",
    "    def __init__(self, resources, tasks):\n",
    "        self.resources = resources  # Available resources (e.g., budget, time)\n",
    "        self.tasks = tasks  # List of tasks with utilities and resource requirements\n",
    "\n",
    "    def evaluate_utility(self, task, allocated_resources):\n",
    "        # A simple utility function (replace with a more complex one if needed)\n",
    "        if allocated_resources >= task[\"resource_requirements\"]:\n",
    "          return task[\"utility\"] * (allocated_resources / task[\"resource_requirements\"]) # Higher utility for more resources\n",
    "        else:\n",
    "          return 0 # Cannot perform the task\n",
    "\n",
    "    def allocate_resources(self):\n",
    "        remaining_resources = self.resources\n",
    "        allocation_plan = {}\n",
    "\n",
    "        sorted_tasks = sorted(self.tasks, key=lambda task: task[\"utility\"], reverse=True)\n",
    "\n",
    "        for task in sorted_tasks:\n",
    "            # Allocate resources if they are available\n",
    "            if remaining_resources >= task[\"resource_requirements\"]:\n",
    "                allocated_amount = task[\"resource_requirements\"]\n",
    "                allocation_plan[task[\"name\"]] = allocated_amount\n",
    "                remaining_resources -= allocated_amount\n",
    "            else:\n",
    "                allocation_plan[task[\"name\"]] = 0 # No resources for this task\n",
    "\n",
    "        return allocation_plan\n",
    "\n",
    "    def act(self):\n",
    "        allocation_plan = self.allocate_resources()\n",
    "\n",
    "        total_utility = 0\n",
    "        for task_name, allocated_resources in allocation_plan.items():\n",
    "          task = next((task for task in self.tasks if task[\"name\"] == task_name), None)\n",
    "          if task:\n",
    "            utility = self.evaluate_utility(task, allocated_resources)\n",
    "            total_utility += utility\n",
    "            print(f\"Task: {task_name}, Allocated Resources: {allocated_resources}, Utility: {utility}\")\n",
    "\n",
    "        print(f\"Total Utility Achieved: {total_utility}\")\n",
    "\n",
    "# Example usage\n",
    "tasks = [\n",
    "    {\"name\": \"Task A\", \"utility\": 10, \"resource_requirements\": 5},\n",
    "    {\"name\": \"Task B\", \"utility\": 5, \"resource_requirements\": 2},\n",
    "    {\"name\": \"Task C\", \"utility\": 8, \"resource_requirements\": 3},\n",
    "]\n",
    "\n",
    "agent = ResourceAllocationAgent(resources=10, tasks=tasks)\n",
    "agent.act()"
   ],
   "metadata": {
    "id": "whlj5tmqxA82",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5f218e6a-0715-417e-fbc6-ae7e300d18c5"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Task: Task A, Allocated Resources: 5, Utility: 10.0\n",
      "Task: Task C, Allocated Resources: 3, Utility: 8.0\n",
      "Task: Task B, Allocated Resources: 2, Utility: 5.0\n",
      "Total Utility Achieved: 23.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 4: Utility-Based Agent**:\n",
    "   - **Description**: Create an agent that not only reaches the goal but also maximizes a utility function, such as collecting items of value along the way.\n",
    "   - **Requirements**: The agent should evaluate different paths based on their utility and choose the most beneficial one.\n"
   ],
   "metadata": {
    "id": "AKQKi2YRM0d2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**5- Learning Agents:** These agents have the ability to learn from their experiences and improve their performance over time. They can adapt to new situations by updating their knowledge base and decision-making processes. More will be introduced next labs.  "
   ],
   "metadata": {
    "id": "kc0SFmauw2DN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Learning Agent Example (Simple Reinforcement Learning)\n",
    "\n",
    "import random\n",
    "\n",
    "class LearningAgent:\n",
    "    def __init__(self, actions):\n",
    "        self.actions = actions\n",
    "        self.q_table = {}  # Q-table to store Q-values\n",
    "        self.learning_rate = 0.1\n",
    "        self.discount_factor = 0.9\n",
    "        self.exploration_rate = 0.1\n",
    "\n",
    "    def get_q_value(self, state, action):\n",
    "        return self.q_table.get((state, action), 0)\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if random.uniform(0, 1) < self.exploration_rate:\n",
    "            # Explore: Choose a random action\n",
    "            return random.choice(self.actions)\n",
    "        else:\n",
    "            # Exploit: Choose the action with the highest Q-value\n",
    "            q_values = [self.get_q_value(state, action) for action in self.actions]\n",
    "            return self.actions[q_values.index(max(q_values))]\n",
    "\n",
    "    def learn(self, state, action, reward, next_state):\n",
    "        # Q-learning update rule\n",
    "        old_q_value = self.get_q_value(state, action)\n",
    "        next_max_q = max([self.get_q_value(next_state, a) for a in self.actions])\n",
    "        new_q_value = (1 - self.learning_rate) * old_q_value + self.learning_rate * (reward + self.discount_factor * next_max_q)\n",
    "        self.q_table[(state, action)] = new_q_value\n",
    "\n",
    "# Example usage (simplified environment)\n",
    "\n",
    "actions = [\"left\", \"right\"]  # Possible actions\n",
    "agent = LearningAgent(actions)\n",
    "environment_states = {\n",
    "    \"A\": {\"left\": (\"B\", -1), \"right\": (\"C\", 1)},\n",
    "    \"B\": {\"left\": (\"A\", -1), \"right\": (\"D\", 10)},\n",
    "    \"C\": {\"left\": (\"A\", -1), \"right\": (\"E\", -5)},\n",
    "    \"D\": {\"left\": (\"B\", -1), \"right\": (\"D\", 10)}, # Example of terminal state with high reward\n",
    "    \"E\": {\"left\": (\"C\", -1), \"right\": (\"E\", -5)}, # Example of terminal state with negative reward\n",
    "\n",
    "}\n",
    "current_state = \"A\"\n",
    "\n",
    "for episode in range(100): # Run for 100 episodes\n",
    "  current_state = \"A\"  # Reset to initial state at start of each episode\n",
    "  for _ in range(10): # Limit episode steps\n",
    "      action = agent.choose_action(current_state)\n",
    "      next_state, reward = environment_states[current_state][action]\n",
    "      agent.learn(current_state, action, reward, next_state)\n",
    "      current_state = next_state\n",
    "\n",
    "# Print learned Q-values\n",
    "print(\"Learned Q-values:\")\n",
    "for (state, action), q_value in agent.q_table.items():\n",
    "    print(f\"State: {state}, Action: {action}, Q-value: {q_value}\")"
   ],
   "metadata": {
    "id": "6KqS9NWUyO0I",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d28ce4b6-fb27-45a7-9a6d-16383e12274f"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Learned Q-values:\n",
      "State: A, Action: left, Q-value: 88.27688049680964\n",
      "State: B, Action: right, Q-value: 99.69883399090406\n",
      "State: D, Action: left, Q-value: 83.05368017675363\n",
      "State: D, Action: right, Q-value: 99.85739101869719\n",
      "State: A, Action: right, Q-value: 2.189914374527203\n",
      "State: C, Action: left, Q-value: 18.77998713902596\n",
      "State: C, Action: right, Q-value: -1.355\n",
      "State: E, Action: left, Q-value: -0.2423657715306539\n",
      "State: E, Action: right, Q-value: -0.5\n",
      "State: B, Action: left, Q-value: 28.0412587556315\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 5: Learning Agents:**\n",
    "\n",
    "Try to understand the basic steps in this code, then write down your step-by-step explanation.\n",
    "\n",
    "Reinforcement Learning* algorithms will be the topic of next week"
   ],
   "metadata": {
    "id": "NeeuvqfWKnJN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 6: Future is Agentic**\n",
    "\n",
    "Listen to the video uploaded to Canvas by one of AI pioneers (Andrew NG) about a future powered by AI agents... After that please answer the following questions:\n",
    "\n",
    "\n",
    "What is an agentic *workflow*, and how does it differ from a non-agentic workflow?\n",
    "\n",
    "Can you provide real-world examples of agentic workflows beyond those mentioned in the video?\n",
    "\n",
    "How can agentic workflows be applied to various industries, such as healthcare, finance, or education?\n",
    "\n",
    "As AI agents become more autonomous, what ethical considerations should be taken into account?\n",
    "\n",
    "How can we ensure that AI agents are used responsibly and ethically?\n",
    "\n",
    "What are the potential societal implications of widespread adoption of AI agents?\n"
   ],
   "metadata": {
    "id": "fiIm6nnFDQSF"
   }
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n# Dataset Loader and Ground Truth Pairing for FTE-HARM Validation\n\nThis section implements a comprehensive dataset loading and ground truth pairing system for forensic log analysis validation. The system enables rigorous validation of FTE-HARM (Forensic Triage Entity - Hypothesis Assessment Risk Model) against known attack patterns.\n\n## Purpose\n\n**Why Ground Truth Pairing is Critical:**\n- **Validation Requirement:** FTE-HARM's hypothesis scoring must be validated against known attack patterns\n- **Ground Truth Necessity:** Without ground truth labels, we cannot measure precision, recall, or accuracy\n- **Dataset Pairing:** Log files and ground truth must be matched correctly to ensure evaluation validity\n- **Forensic Accountability:** Every triage decision must be traceable to verified evidence\n\n## Supported Ground Truth Formats\n\n| Format | Extension | Example |\n|--------|-----------|---------|\n| Line-by-Line | `.log`, `.txt` | `benign,0,none` or `malicious,1,privilege_escalation` |\n| CSV with Line Numbers | `.csv` | `line_number,label,attack_type,confidence` |\n| JSON Temporal | `.json` | Attack windows with start/end times |",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Import the dataset loader module\n# First, let's ensure we're in the correct directory and the module is available\n\nimport sys\nimport os\n\n# Mount Google Drive (for Colab environment)\ntry:\n    from google.colab import drive\n    drive.mount('/content/drive')\n    IN_COLAB = True\nexcept ImportError:\n    IN_COLAB = False\n    print(\"Not running in Colab - using local paths\")\n\n# Add module path\nif IN_COLAB:\n    # If running in Colab, clone or copy the module\n    module_path = '/content/drive/My Drive/thesis'\n    if os.path.exists(module_path):\n        sys.path.insert(0, module_path)\nelse:\n    # Local development\n    module_path = os.path.dirname(os.path.abspath('__file__'))\n    sys.path.insert(0, module_path)\n\n# Import the dataset loader\nfrom dataset_loader import (\n    DatasetConfig,\n    DatasetScanner,\n    DatasetPairer,\n    GroundTruthLoader,\n    DatasetValidator,\n    DatasetStatsGenerator,\n    DatasetIterator,\n    FTEHARMValidator,\n    load_and_pair_datasets,\n    validate_datasets,\n    iterate_with_groundtruth,\n    GroundTruthEntry,\n    DatasetPair,\n    ValidationResult,\n    DatasetStatistics,\n    GroundTruthFormat\n)\n\nprint(\"Dataset loader module imported successfully!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 1: Configure Dataset Paths\n\nConfigure the paths to your forensic log datasets. The default configuration expects the following structure:\n\n```\n/content/drive/My Drive/thesis/dataset/\n├── grp1/                    # Group 1: Primary datasets\n│   ├── rm/                  # RussellMitchell AITv2 dataset\n│   │   ├── log_auth.log     # SSH authentication logs (raw)\n│   │   ├── label_auth.log   # Ground truth for log_auth.log\n│   │   └── ...\n│   └── santos/              # Santos DNS exfiltration dataset\n│       ├── dns_queries.log  # DNS query logs (raw)\n│       ├── dns_labels.log   # Ground truth for dns_queries.log\n│       └── ...\n└── grp2/                    # Group 2: Secondary/validation datasets\n    └── ...\n```",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Configure dataset paths\n# Modify these paths according to your directory structure\n\nif IN_COLAB:\n    DATASET_PATHS = {\n        'grp1': '/content/drive/My Drive/thesis/dataset/grp1',\n        'grp2': '/content/drive/My Drive/thesis/dataset/grp2'\n    }\nelse:\n    # Local development paths (modify as needed)\n    DATASET_PATHS = {\n        'grp1': './datasets/grp1',\n        'grp2': './datasets/grp2'\n    }\n\n# Create custom configuration\nconfig = DatasetConfig()\nconfig.DATASET_PATHS = DATASET_PATHS\n\n# Display configuration\nprint(\"Dataset Configuration:\")\nprint(\"=\" * 60)\nfor group, path in DATASET_PATHS.items():\n    exists = os.path.exists(path)\n    status = \"EXISTS\" if exists else \"NOT FOUND\"\n    print(f\"  {group}: {path} [{status}]\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 2: Scan Dataset Directories\n\nScan the configured directories to discover log files and potential ground truth files.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Scan all dataset directories\nscanner = DatasetScanner(config)\n\nprint(\"Scanning dataset directories...\")\nprint(\"=\" * 60)\n\nall_datasets = {}\nfor group_name, group_path in DATASET_PATHS.items():\n    if os.path.exists(group_path):\n        group_datasets = scanner.scan_directory(group_path)\n        print(f\"\\n{group_name.upper()} ({group_path}):\")\n        \n        if not group_datasets:\n            print(\"  No datasets found\")\n        else:\n            for subdir, info in group_datasets.items():\n                print(f\"  {subdir}/\")\n                print(f\"    Log files: {info['log_files']}\")\n                print(f\"    Label files: {info['label_files']}\")\n                \n                # Store with group prefix\n                all_datasets[f\"{group_name}/{subdir}\"] = info\n    else:\n        print(f\"\\n{group_name.upper()}: Directory not found\")\n\nprint(f\"\\nTotal subdirectories scanned: {len(all_datasets)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 3: Pair Log Files with Ground Truth\n\nMatch each log file with its corresponding ground truth annotation file using multiple pairing rules:\n\n1. **Prefix match:** `log_X.log` → `label_X.log`\n2. **Suffix match:** `X.log` → `X_labels.csv`\n3. **Root name match:** `X.log` → `X_gt.txt`",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Create dataset pairs\npairer = DatasetPairer(config)\n\nif all_datasets:\n    dataset_pairs = pairer.create_dataset_pairs(all_datasets)\n    \n    print(\"Dataset Pairing Results:\")\n    print(\"=\" * 60)\n    \n    paired_count = sum(1 for p in dataset_pairs if p.paired)\n    unpaired_count = len(dataset_pairs) - paired_count\n    \n    print(f\"\\nTotal log files: {len(dataset_pairs)}\")\n    print(f\"Successfully paired: {paired_count}\")\n    print(f\"Unpaired: {unpaired_count}\")\n    \n    print(\"\\nDetailed Pairing:\")\n    print(\"-\" * 60)\n    \n    for pair in dataset_pairs:\n        status = \"PAIRED\" if pair.paired else \"UNPAIRED\"\n        log_name = os.path.basename(pair.log_file)\n        label_name = os.path.basename(pair.label_file) if pair.label_file else \"N/A\"\n        format_name = pair.ground_truth_format.value if pair.paired else \"N/A\"\n        \n        print(f\"[{status}] {pair.dataset_name}\")\n        print(f\"  Log: {log_name}\")\n        print(f\"  Label: {label_name}\")\n        print(f\"  Format: {format_name}\")\n        print()\nelse:\n    dataset_pairs = []\n    print(\"No datasets found to pair. Please check your dataset paths.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 4: Validate Dataset Integrity\n\nValidate that paired datasets are correctly matched:\n- Check that files exist\n- Verify line counts match (for line-by-line format)\n- Ensure all referenced lines exist (for CSV format)\n- Validate ground truth label values",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Validate all dataset pairs\nvalidator = DatasetValidator()\n\nif dataset_pairs:\n    print(\"Validating Dataset Pairs...\")\n    print(\"=\" * 60)\n    \n    validation_results = validator.validate_all(dataset_pairs)\n    \n    valid_count = sum(1 for r in validation_results.values() if r.valid)\n    invalid_count = len(validation_results) - valid_count\n    \n    print(f\"\\nValidation Summary:\")\n    print(f\"  Valid: {valid_count}\")\n    print(f\"  Invalid: {invalid_count}\")\n    \n    # Show details for any invalid or warning cases\n    print(\"\\nValidation Details:\")\n    print(\"-\" * 60)\n    \n    for dataset_name, result in validation_results.items():\n        if not result.valid:\n            print(f\"\\n[INVALID] {dataset_name}\")\n            for error in result.errors:\n                print(f\"  ERROR: {error}\")\n            for warning in result.warnings:\n                print(f\"  WARNING: {warning}\")\n        elif result.warnings:\n            print(f\"\\n[VALID with warnings] {dataset_name}\")\n            for warning in result.warnings:\n                print(f\"  WARNING: {warning}\")\n        else:\n            print(f\"[VALID] {dataset_name}\")\nelse:\n    print(\"No dataset pairs to validate.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 5: Generate Dataset Statistics\n\nGenerate comprehensive statistics about the paired datasets, including:\n- Total log entries\n- Malicious vs benign distribution\n- Attack type breakdown\n- Per-group statistics",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Generate dataset statistics\nstats_generator = DatasetStatsGenerator()\n\nif dataset_pairs:\n    paired_datasets = [p for p in dataset_pairs if p.paired]\n    \n    if paired_datasets:\n        print(\"Generating Dataset Statistics...\")\n        stats = stats_generator.generate_stats(dataset_pairs)\n        \n        # Print detailed report\n        stats_generator.print_report(stats)\n    else:\n        print(\"No paired datasets available for statistics generation.\")\nelse:\n    print(\"No datasets available for statistics.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 6: Iterate Through Dataset Pairs\n\nIterate through matched log-ground truth pairs for FTE-HARM processing. This demonstrates how to access each log entry along with its corresponding ground truth label.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Example: Iterate through dataset pairs with a simple processor\niterator = DatasetIterator()\n\ndef example_processor(log_line, ground_truth, line_number):\n    \"\"\"\n    Example processing function for each log entry.\n    \n    In real FTE-HARM usage, this would:\n    1. Extract entities from log_line using NER\n    2. Score all hypotheses\n    3. Make triage decision\n    \n    Returns processing result for collection.\n    \"\"\"\n    # Get ground truth values\n    if isinstance(ground_truth, GroundTruthEntry):\n        is_malicious = ground_truth.is_malicious\n        attack_type = ground_truth.attack_type\n    else:\n        is_malicious = ground_truth.get('binary', 0) == 1\n        attack_type = ground_truth.get('attack_type', 'unknown')\n    \n    return {\n        'line': line_number,\n        'log_preview': log_line[:50] + '...' if len(log_line) > 50 else log_line,\n        'is_malicious': is_malicious,\n        'attack_type': attack_type\n    }\n\n# Process a sample of entries (limit for demonstration)\nif dataset_pairs:\n    paired_datasets = [p for p in dataset_pairs if p.paired]\n    \n    if paired_datasets:\n        print(\"Iterating through dataset pairs...\")\n        print(\"=\" * 60)\n        \n        # Process first 10 entries as example\n        results = iterator.iterate_pairs(paired_datasets[:1], example_processor, verbose=True)\n        \n        print(f\"\\nProcessed {len(results)} log entries\")\n        print(\"\\nSample results (first 5):\")\n        print(\"-\" * 60)\n        \n        for r in results[:5]:\n            gt = r['result']\n            status = \"MALICIOUS\" if gt['is_malicious'] else \"BENIGN\"\n            print(f\"Line {gt['line']} [{status}] {gt['attack_type']}\")\n            print(f\"  {gt['log_preview']}\")\n            print()\n    else:\n        print(\"No paired datasets available for iteration.\")\nelse:\n    print(\"No datasets available for iteration.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 7: FTE-HARM Validation Integration\n\nThis section demonstrates how to integrate the dataset loader with FTE-HARM hypothesis validation. The `FTEHARMValidator` class provides a complete workflow for:\n\n1. Loading paired datasets\n2. Extracting entities from logs\n3. Scoring hypotheses\n4. Comparing predictions with ground truth\n5. Calculating validation metrics (precision, recall, F1, accuracy)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Example FTE-HARM Validation Integration\n# Note: This requires actual FTE-HARM entity extraction and hypothesis scoring functions\n\n# Placeholder functions for demonstration (replace with actual implementations)\ndef placeholder_entity_extractor(log_line):\n    \"\"\"\n    Placeholder entity extractor.\n    \n    In real implementation, this would use the NER transformer model\n    to extract entities like UserName, IPAddress, ProcessName, etc.\n    \"\"\"\n    # Return mock entities for demonstration\n    return {\n        'UserName': 'admin' if 'admin' in log_line.lower() else 'user',\n        'ProcessName': 'sshd' if 'ssh' in log_line.lower() else 'unknown',\n        'IPAddress': '192.168.1.1'\n    }\n\ndef placeholder_hypothesis_scorer(entities, hypothesis_config):\n    \"\"\"\n    Placeholder hypothesis scorer.\n    \n    In real implementation, this would calculate P(H|E) using\n    Bayesian inference with the hypothesis configuration.\n    \"\"\"\n    # Return mock score based on entities\n    if entities.get('UserName') == 'admin':\n        return {'p_score': 0.65}\n    return {'p_score': 0.25}\n\n# Example hypothesis configurations\nexample_hypothesis_configs = {\n    'privilege_escalation': {\n        'name': 'Privilege Escalation',\n        'prior': 0.15,\n        'required_entities': ['UserName', 'ProcessName'],\n        'evidence_weights': {'UserName': 0.3, 'ProcessName': 0.4}\n    },\n    'lateral_movement': {\n        'name': 'Lateral Movement', \n        'prior': 0.10,\n        'required_entities': ['IPAddress', 'UserName'],\n        'evidence_weights': {'IPAddress': 0.5, 'UserName': 0.3}\n    }\n}\n\n# Run validation (if datasets are available)\nif dataset_pairs:\n    paired_datasets = [p for p in dataset_pairs if p.paired]\n    \n    if paired_datasets:\n        print(\"Running FTE-HARM Validation...\")\n        print(\"=\" * 60)\n        print(\"(Using placeholder functions - replace with actual implementations)\")\n        print()\n        \n        fte_validator = FTEHARMValidator()\n        \n        # Run validation on a subset for demonstration\n        validation_results = fte_validator.validate(\n            pairs=paired_datasets[:1],  # Limit for demo\n            entity_extractor=placeholder_entity_extractor,\n            hypothesis_scorer=placeholder_hypothesis_scorer,\n            hypothesis_configs=example_hypothesis_configs,\n            triage_threshold=0.45\n        )\n        \n        # Print validation report\n        fte_validator.print_validation_report(validation_results)\n    else:\n        print(\"No paired datasets available for FTE-HARM validation.\")\nelse:\n    print(\"No datasets available. Showing example validation report structure:\")\n    print()\n    print(\"=\" * 60)\n    print(\"FTE-HARM VALIDATION REPORT (EXAMPLE)\")\n    print(\"=\" * 60)\n    print(\"Metrics that would be calculated:\")\n    print(\"  - Precision: TP / (TP + FP)\")\n    print(\"  - Recall: TP / (TP + FN)\")  \n    print(\"  - F1 Score: 2 * (P * R) / (P + R)\")\n    print(\"  - Accuracy: (TP + TN) / Total\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Validation Checklist\n\nBefore proceeding to FTE-HARM hypothesis testing, ensure:\n\n- [ ] Dataset directories scanned successfully\n- [ ] All log files identified\n- [ ] Ground truth files located\n- [ ] Log-ground truth pairing completed\n- [ ] Dataset integrity validated\n- [ ] No line count mismatches\n- [ ] Ground truth format understood\n- [ ] Dataset statistics generated\n- [ ] Iteration workflow tested\n- [ ] Ready for FTE-HARM integration\n\n## Quick Reference: Convenience Functions\n\n```python\n# One-liner to load and pair all datasets\npairs, stats = load_and_pair_datasets(DATASET_PATHS)\n\n# Validate all pairs\nvalidation_results = validate_datasets(pairs)\n\n# Iterate with custom processor\nresults = iterate_with_groundtruth(pairs, my_processor_fn)\n```\n\n## Expected Dataset Statistics\n\n| Dataset | Total Logs | Malicious % | Primary Attack Types |\n|---------|-----------|-------------|---------------------|\n| RussellMitchell AITv2 | ~50,000 | ~15% | privilege_escalation, lateral_movement |\n| Santos DNS | ~100,000 | ~5% | exfiltration, command_and_control |",
   "metadata": {}
  }
 ]
}